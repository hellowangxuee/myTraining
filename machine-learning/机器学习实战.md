算法
------------
### K-近邻算法
K-近邻算法采用测量不同特征值之间的距离方法进行分类。  
K-近邻算法(KNN)工作原理：存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即样本集中每一数据与所属分类的对应关系。
输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据(最近邻)的分类标签。通常选择
样本数据集中前 K 个最相似的数据，且 K 是不大于 20  的整数，最后选择 K 个中出现次数最多的分类，作为新数据的分类。  
#### 准备：使用Python 导入数据
在KNN.py 中增加如下代码：代码中导入了两个包：科学计算包 NumPy;运算符模块  
```Python
from numpy import *
import operator

def createDataSet():
	group = array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])
	labels = ['A','A','B','B']
	return group, labels
```
切换到 KNN.py 所在的文件夹，  
```Python
>>> import KNN
>>> group,labels = KNN.createDataSet()
>>> group
array([[ 1. ,  1.1],
       [ 1. ,  1. ],
       [ 0. ,  0. ],
       [ 0. ,  0.1]])
>>> labels
['A', 'A', 'B', 'B']
```
为了简单，通常每个数据点只使用两个特征。  
向量 labels 包含了每个数据点的标签信息， labels 包含的元素个数等于 group 矩阵行数。  
#### 实施 KNN 算法
##### 对未知类别属性的数据集中的每个点依次执行以下操作：
1. 计算一直类别数据据中的店与当前点之间的距离；
2. 按照距离递增依次排序；
3. 选取与当前距离最小的 K 个点；
4. 确定前 K 个点所在类别的出现频率；
5. 返回前 K 个点出现频率最高的类别作为当前的预测分类。
```python
def classify0(inX, dataSet, labels, k):
	dataSetSize = dataSet.shape[0]
	diffMat = tile(inX, (dataSetSize,1)) - dataSet
	sqDiffMat = diffMat**2
	sqDistances = sqDiffMat.sum(axis=1)
	distances = sqDistances**0.5
	sortedDistIndicies = distances.argsort()
	classCount = {}
	for i in range (k):
		voteIlabel = labels[sortedDistIndicies[i]]
		classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1
	sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)
	return sortedClassCount[0][0]
```
classify0() 函数有四个输入参数：用于分类的输入向量是 inX；输入的训练样本集为 dataSet；标签向量为 labels；最后参数 K 表示用于选择最近邻居的数目。  
```Python
>>> import KNN
>>> group, labels = KNN.createDataSet()
>>> KNN.classify0([0,0], group, labels, 3)
'B'
```
到目前为止，已经构造了第一个分类器。  
k-近邻算法是分类数据最简单最有效的算法，他是基于实例的学习，使用算法时必须有接近实际数据的训练样本数据。k-近邻算法必须保存全部数据集，如果训练
数据集很大，必须使用大量的存储空间。另外，他无法给出任何数据的基础结构信息，因此无法知晓实例样本和典型实例样本具有什么特征。  
### 决策树
#### 适用数据类型
数值型和标称型。  
#### 优点
计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。  
#### 缺点
可能会产生过度匹配问题。  
构造决策树时需要找到划分数据的决定性特征，此处采用 ID3算法。  
#### 信息增益
划分数据集原则：将无序的数据变得更加有序。   
划分数据集前后信息发生的变化称为信息增益。获得信息增益最高的特征就是最好的选择。  
#### 熵
定义：信息的期望值  

